import sys
import gi
import time
import pyds
from collections import deque

gi.require_version("Gst", "1.0")
from gi.repository import Gst, GLib

# Initialize GStreamer
Gst.init(None)

# Define paths for the DeepStream configuration files and model
config_file = "/path/to/deepstream/config_file.txt"
model_path = "/path/to/yolov8/model"

# Create a deque to store streams
streams = deque()

# Initialize the DeepStream pipeline
def create_pipeline(num_sources):
    # Create an empty pipeline
    pipeline = Gst.Pipeline()

    # For each camera source, create the necessary elements
    for i in range(num_sources):
        source = Gst.ElementFactory.make("v4l2src", f"source_{i}")
        source.set_property("device", f"/dev/video{i}")
        cap_filter = Gst.ElementFactory.make("capsfilter", f"filter_{i}")
        caps = Gst.Caps.from_string("video/x-raw, format=BGRx")
        cap_filter.set_property("caps", caps)

        # Convert frames from video stream to DeepStream compatible format
        nvvidconv = Gst.ElementFactory.make("nvvideoconvert", f"nvconv_{i}")
        nvvideoconvert = Gst.ElementFactory.make("nvvidconv", f"nvvconv_{i}")
        # Set the model for inference (YOLOv8 or any other pre-trained model)
        pgie = Gst.ElementFactory.make("nvinfer", f"pgie_{i}")
        pgie.set_property("config-file-path", config_file)
        pgie.set_property("model-engine-file", model_path)

        # Output sink for showing the inference result
        nvdsosd = Gst.ElementFactory.make("nvdsosd", f"osd_{i}")
        sink = Gst.ElementFactory.make("nveglglessink", f"sink_{i}")

        # Add the elements to the pipeline
        pipeline.add(source, cap_filter, nvvidconv, pgie, nvdsosd, sink)
        source.link(cap_filter)
        cap_filter.link(nvvidconv)
        nvvidconv.link(pgie)
        pgie.link(nvdsosd)
        nvdsosd.link(sink)

        streams.append(pipeline)

    return pipeline


# Process inference for each camera input
def run_inference():
    # Create the pipeline with 2 camera streams for demonstration
    pipeline = create_pipeline(2)

    # Start playing the pipeline
    pipeline.set_state(Gst.State.PLAYING)

    try:
        # Start the GLib main loop for continuous processing
        loop = GLib.MainLoop()
        loop.run()

    except KeyboardInterrupt:
        # Handle user interruption
        print("Shutting down the pipeline...")
        pipeline.set_state(Gst.State.NULL)
        loop.quit()


if __name__ == "__main__":
    run_inference()
